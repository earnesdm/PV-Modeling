{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PWtyDuWwkhKy",
        "outputId": "8d567e14-5346-469d-d09f-fbc01cf9cb4d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive/\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import sampler\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as T\n",
        "import numpy as np\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/', force_remount=True)\n",
        "\n",
        "import sys\n",
        "sys.path.insert(0,'/content/gdrive/My Drive/Colab Notebooks')\n",
        "\n",
        "## Loss function and effiency metrics are already provided to you.\n",
        "from project_utilities import Loss\n",
        "from project_utilities import efficiency\n",
        "from project_utilities import ValueSet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "5GYgix6ckki4"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "cd into project data"
      ],
      "metadata": {
        "id": "rEBygfNlsweK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/gdrive/MyDrive/Project/data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NdCV7J1hlE-q",
        "outputId": "6bab2a98-fbbb-4491-e758-6d4d837e8593"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/Project/data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xh-sfXsclIUd",
        "outputId": "3d1c5b43-58ba-4593-c22f-6f064c9c94a4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bi_rnn.pt                Set_1.npz   Set_36.npz  Set_52.npz  Set_69.npz\n",
            "linear.pt                Set_20.npz  Set_37.npz  Set_53.npz  Set_6.npz\n",
            "RCNN_h64_l3_loss0351.pt  Set_21.npz  Set_38.npz  Set_54.npz  Set_70.npz\n",
            "RCNN_h64_l3_loss0356.pt  Set_22.npz  Set_39.npz  Set_55.npz  Set_71.npz\n",
            "RCNN_h64_l3.pt           Set_23.npz  Set_3.npz   Set_56.npz  Set_72.npz\n",
            "RCNN.pt                  Set_24.npz  Set_40.npz  Set_57.npz  Set_73.npz\n",
            "res_cnn.pt               Set_25.npz  Set_41.npz  Set_58.npz  Set_74.npz\n",
            "RNN.pt                   Set_26.npz  Set_42.npz  Set_59.npz  Set_75.npz\n",
            "Set_10.npz               Set_27.npz  Set_43.npz  Set_5.npz   Set_76.npz\n",
            "Set_11.npz               Set_28.npz  Set_44.npz  Set_60.npz  Set_77.npz\n",
            "Set_12.npz               Set_29.npz  Set_45.npz  Set_61.npz  Set_78.npz\n",
            "Set_13.npz               Set_2.npz   Set_46.npz  Set_62.npz  Set_79.npz\n",
            "Set_14.npz               Set_30.npz  Set_47.npz  Set_63.npz  Set_7.npz\n",
            "Set_15.npz               Set_31.npz  Set_48.npz  Set_64.npz  Set_80.npz\n",
            "Set_16.npz               Set_32.npz  Set_49.npz  Set_65.npz  Set_8.npz\n",
            "Set_17.npz               Set_33.npz  Set_4.npz   Set_66.npz  Set_9.npz\n",
            "Set_18.npz               Set_34.npz  Set_50.npz  Set_67.npz\n",
            "Set_19.npz               Set_35.npz  Set_51.npz  Set_68.npz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MyDataset(torch.utils.data.Dataset):\n",
        "  def __init__(self, setID):\n",
        "        'Initialization'\n",
        "        npz_files_content = np.load(\"./Set_\"+str(setID)+\".npz\")\n",
        "        self.X_set = torch.tensor(npz_files_content['X'])\n",
        "        self.y_set = torch.tensor(npz_files_content['y'])\n",
        "\n",
        "        # sets all nans to 0.0\n",
        "        self.y_set[self.y_set != self.y_set] = 0.0 \n",
        "        self.X_set[self.X_set != self.X_set] = 0.0 \n",
        "  def __len__(self):\n",
        "        'Denotes the total number of samples'\n",
        "        return len(self.y_set)\n",
        "  def __getitem__(self, index):\n",
        "        'Generates one sample of data'\n",
        "        # Select sample\n",
        "        X = self.X_set[index]\n",
        "        y = self.y_set[index]\n",
        "        return X, y"
      ],
      "metadata": {
        "id": "Nnc5DW2plMoj"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "load loss model"
      ],
      "metadata": {
        "id": "FjsjrVVWs0lP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_model = Loss(0.00001)"
      ],
      "metadata": {
        "id": "5CxoZrkDlSew"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "rnn model"
      ],
      "metadata": {
        "id": "7xYr0mNLs24J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Bidirectional recurrent neural network (many-to-one)\n",
        "class BiRNN_2(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers):\n",
        "        super(BiRNN_2, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.lstm_1 = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, bidirectional=True)\n",
        "        #self.lstm_2 = nn.LSTM(128, 1, 1, batch_first=True, bidirectional=False)\n",
        "        self.lstm_2 = nn.LSTM(2*hidden_size, 1, 1, batch_first=True, bidirectional=True)\n",
        "    \n",
        "    def forward(self, x): \n",
        "        x = torch.transpose(x, 2, 1)\n",
        "        # x dim: [batch size, sentence length, feature dim]    \n",
        "      \n",
        "        out, _ = self.lstm_1(x)  # out: tensor of shape (batch_size, seq_length, hidden_size*2)\n",
        "        # output dim: [batch size, sentence length, hidden dim*2]\n",
        "        # hidden dim: [2, batch size, hidden dim]\n",
        "\n",
        "        out, _ = self.lstm_2(out)\n",
        "\n",
        "        # average pooling\n",
        "        out = (out[:, :, 0] + out[:, :, 1])/2\n",
        "\n",
        "        return out.squeeze()"
      ],
      "metadata": {
        "id": "PRqRcXivlYyt"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "validate function used from evaluation"
      ],
      "metadata": {
        "id": "I7Hg4GaTs4pr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def validate(model, dataset_num=11): \n",
        "    loss_val = [] \n",
        "    eff = ValueSet(0, 0, 0, 0) \n",
        "    # switch to evaluate mode\n",
        "    #model.to(\"cpu\") \n",
        "    model.eval() \n",
        "    with torch.no_grad(): \n",
        "        #val_set = MyDataset(setID+1) \n",
        "        val_set = MyDataset(dataset_num)\n",
        "        val_generator = torch.utils.data.DataLoader(val_set,  \n",
        "                                                    batch_size=64,  \n",
        "                                                    shuffle=True) \n",
        "        #print(setID) \n",
        "        for X_val, y_val in val_generator: \n",
        "          # Forward pass \n",
        "          X_val = X_val.to(DEVICE)\n",
        "          y_val = y_val.to(DEVICE)\n",
        "          val_outputs = model(X_val) \n",
        "          loss_output = loss_model.forward(val_outputs, y_val) \n",
        "          loss_val.append(loss_output) \n",
        "          for label, output in zip(y_val.cpu().numpy(), val_outputs.cpu().numpy()):\n",
        "              eff += efficiency(label, output, difference = 5.0,  \n",
        "                                threshold = 1e-2, integral_threshold = 0.2,  \n",
        "                                min_width = 3) \n",
        "    return sum(loss_val)/len(loss_val), eff.eff_rate, eff.fp_rate "
      ],
      "metadata": {
        "id": "tLvrld9SlfqK"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "creates model"
      ],
      "metadata": {
        "id": "Ij1NhIz_s-qh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = BiRNN_2(input_size=4, hidden_size=64, num_layers=3)\n",
        "\n",
        "model = model.to(DEVICE)"
      ],
      "metadata": {
        "id": "cKkpPmkslhsD"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "loads state_dict"
      ],
      "metadata": {
        "id": "5f7lja50tAWT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load('./RCNN_h64_l3_loss0351.pt'))\n",
        "model.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1gWLznhSoDdI",
        "outputId": "a13784a3-56cd-435c-a4be-a459fb140ff0"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BiRNN_2(\n",
              "  (lstm_1): LSTM(4, 64, num_layers=3, batch_first=True, bidirectional=True)\n",
              "  (lstm_2): LSTM(128, 1, batch_first=True, bidirectional=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "evaluates the model on new data. (Note: the data is assumed to be in google drive under Project/data and is expected to have the name Set_81.npz.)"
      ],
      "metadata": {
        "id": "3-T-7quXtD7w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_val, eff_rate, fp_rate = validate(model, dataset_num=11)"
      ],
      "metadata": {
        "id": "q_pUBXFWq-q5"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Loss: {loss_val}\")\n",
        "print(f\"Eff: {eff_rate}\")\n",
        "print(f\"FP: {fp_rate}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N1kar_rMrBq9",
        "outputId": "66d7244c-4d6f-4ae9-98b6-6f209dee01e4"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.03497587889432907\n",
            "Eff: 0.8650372336503723\n",
            "FP: 0.26294741051789644\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "evaluation code"
      ],
      "metadata": {
        "id": "PbczXS8qtg44"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_val, eff_rate, fp_rate = validate(model, dataset_num=81)"
      ],
      "metadata": {
        "id": "ggBgNW6Wto5e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Loss: {loss_val}\")\n",
        "print(f\"Eff: {eff_rate}\")\n",
        "print(f\"FP: {fp_rate}\")"
      ],
      "metadata": {
        "id": "KsktUHvbtlRG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}